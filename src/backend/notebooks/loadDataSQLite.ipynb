{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import sqlite3\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from pyquadkey2 import quadkey\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLite connection\n",
    "db_Path = \"../../data/quadkeyDB.sqlite\"\n",
    "con = sqlite3.connect(db_Path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table in SQLite if it does not exist\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS data_slice_male_long_lat (\n",
    "    quadkey TEXT,\n",
    "    raster_1 REAL,\n",
    "    raster_2 REAL,\n",
    "    raster_3 REAL,\n",
    "    raster_4 REAL,\n",
    "    raster_5 REAL,\n",
    "    raster_6 REAL,\n",
    "    raster_7 REAL,\n",
    "    raster_8 REAL,\n",
    "    raster_9 REAL,\n",
    "    raster_10 REAL,\n",
    "    raster_11 REAL,\n",
    "    raster_12 REAL,\n",
    "    raster_13 REAL,\n",
    "    raster_14 REAL,\n",
    "    raster_15 REAL,\n",
    "    raster_16 REAL,\n",
    "    raster_17 REAL,\n",
    "    raster_18 REAL,\n",
    "    raster_19 REAL,\n",
    "    raster_20 REAL,\n",
    "    raster_21 REAL,\n",
    "    raster_22 REAL,\n",
    "    raster_23 REAL,\n",
    "    raster_24 REAL,\n",
    "    raster_25 REAL,\n",
    "    raster_26 REAL,\n",
    "    raster_27 REAL,\n",
    "    raster_28 REAL,\n",
    "    raster_29 REAL,\n",
    "    raster_30 REAL\n",
    ");\n",
    "\"\"\"\n",
    "con.execute(create_table_query)\n",
    "con.commit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index for SQLite table\n",
    "con.execute(\"CREATE UNIQUE INDEX IF NOT EXISTS quadkeyIndex ON data_slice_male_long_lat (quadkey);\")\n",
    "con.commit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLite DB Tweaks for performance\n",
    "con.execute(\"PRAGMA synchronous = OFF;\")\n",
    "con.execute(\"PRAGMA cache_size = -500000;  -- 500 MB;\")\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_offset_quadkey(lat, lon, zoom_level, offset_minutes=2.5):\n",
    "    # Convert offset from minutes to degrees\n",
    "    offset_degrees = offset_minutes / 60.0  # 1 minute = 1/60 degrees\n",
    "\n",
    "    # Adjust the latitude and longitude\n",
    "    adjusted_lat = lat + offset_degrees\n",
    "    adjusted_lon = lon + offset_degrees\n",
    "\n",
    "    # Generate the quadkey for the adjusted coordinate\n",
    "    quadkey_str = quadkey.from_geo((adjusted_lat, adjusted_lon), zoom_level)\n",
    "    return quadkey_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_points_vectorized_quadkey(ds):\n",
    "    data_points = []\n",
    "    longs = ds.longitude.values\n",
    "    lats = ds.latitude.values\n",
    "    zoom_level = 13  # Precision level for quadkey generation\n",
    "\n",
    "\n",
    "    lat_grid, lon_grid = np.meshgrid(lats, longs, indexing=\"ij\")\n",
    "    # Flatten the grids for vectorized operations\n",
    "    lat_flat = lat_grid.ravel()\n",
    "    lon_flat = lon_grid.ravel()\n",
    "    # Generate quadkeys for all points\n",
    "    coords = np.column_stack((lat_flat, lon_flat))\n",
    "    quadkeysList = []\n",
    "    for coord in coords:\n",
    "        try:\n",
    "            q1 = quadkey.from_geo(coord, zoom_level)\n",
    "            q2 = get_offset_quadkey(coord[0], coord[1], zoom_level)\n",
    "            quadkeyList = q1.difference(q2)\n",
    "            quadkeysList.append(quadkeyList)\n",
    "        except AssertionError:\n",
    "            print(f\"Invalid coordinate causing AssertionError: {coord}\")\n",
    "    # quadkeys = [quadkey.from_geo(coord, zoom_level).key for coord in coords]\n",
    "    # Extract raster values corresponding to the lat/lon indices\n",
    "    raster_values = []\n",
    "    for i, (lat, lon) in enumerate(coords):\n",
    "        # Find the closest indices in the dataset for the current lat/lon\n",
    "        x_idx = np.abs(lats - lat).argmin()\n",
    "        y_idx = np.abs(longs - lon).argmin()\n",
    "        # Extract the raster values at the closest indices\n",
    "        values = ds.values[:, x_idx, y_idx]  # Adjust if your dataset structure differs\n",
    "        raster_values.append(values)\n",
    "    # Combine quadkeys and raster values\n",
    "    # Loop through each quadkey list and corresponding raster values\n",
    "    for quadkey_list, raster_value_row in zip(quadkeysList, raster_values):\n",
    "        for qkey in quadkey_list:\n",
    "            # Append the quadkey string and raster values as a new data point\n",
    "            data_points.append([qkey.key] + list(raster_value_row))\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    columns = ['quadkey'] + [f'raster_{i + 1}' for i in range(ds.shape[0])]\n",
    "    df = pd.DataFrame(data_points, columns=columns)\n",
    "\n",
    "    # Replace NaN with None to ensure database compatibility\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "\n",
    "    # Remove duplicates based on quadkeys\n",
    "    df = df.drop_duplicates(subset='quadkey')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_table = \"data_slice_male_long_lat\"\n",
    "file_path = \"../../data/gpw_v4_basic_demographic_characteristics_rev11_mt_2010_dens_2pt5_min.nc\"\n",
    "\n",
    "\n",
    "def load_dataset(file_path, lat_slice, lon_slice):\n",
    "    dataset = xr.open_dataset(file_path)\n",
    "    # Process dataset chunk\n",
    "    data_slice = dataset.sel(latitude=lat_slice, longitude=lon_slice)\n",
    "    data_slice = data_slice[\n",
    "        \"Basic Demographic Characteristics, v4.10 (2010): Male, Density, 2.5 arc-minutes\"\n",
    "    ]\n",
    "    return data_slice.compute()\n",
    "\n",
    "\n",
    "def insert_into_db(data_slice):\n",
    "    # Increase the timeout to 30 seconds (default is 5 seconds)\n",
    "    conn = sqlite3.connect(db_path, timeout=300)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        # Batch insert data\n",
    "        placeholders = \", \".join([\"?\"] * len(data_slice.columns))\n",
    "        insert_query = f\"INSERT OR IGNORE INTO {data_table} VALUES ({placeholders})\"\n",
    "        cursor.executemany(insert_query, data_slice.values.tolist())\n",
    "\n",
    "        # Commit the transaction\n",
    "        conn.commit()\n",
    "    except sqlite3.OperationalError as e:\n",
    "        print(f\"Error while inserting data: {e}\")\n",
    "    finally:\n",
    "        # Ensure the connection is closed\n",
    "        conn.close()\n",
    "\n",
    "\n",
    "\n",
    "def process_slice(lat_start, lat_end, lon_start, lon_end):\n",
    "    lat_slice = slice(lat_start, lat_end)\n",
    "    lon_slice = slice(lon_start, lon_end)\n",
    "\n",
    "     # Load the data slice\n",
    "    data_slice = load_dataset(file_path, lat_slice, lon_slice)\n",
    "\n",
    "    # Extract data points with quadkeys\n",
    "    data_slice_quadkey = extract_data_points_vectorized_quadkey(data_slice)\n",
    "\n",
    "    # Insert into the database\n",
    "    insert_into_db(data_slice_quadkey)\n",
    "\n",
    "def load_male_dataset_into_db():\n",
    "    # Define all lat/lon chunks\n",
    "    # Smaller latitude and longitude steps\n",
    "    tasks = [\n",
    "        (lat_start, max(lat_start - 10, -85.05112878), lon_start, min(lon_start + 10, 180))\n",
    "        # full map range\n",
    "        for lat_start in range(85, -85, -1)  \n",
    "        for lon_start in range(-180, 180, 1)\n",
    "        # inhabited area only\n",
    "        # for lat_start in range(80, -56, -10)\n",
    "        # for lon_start in range(-180, 180, 10)\n",
    "        ]\n",
    "\n",
    "\n",
    "    # Process all tasks in parallel\n",
    "    Parallel(n_jobs=-1)(delayed(process_slice)(*task) for task in tasks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute parent levels in quadkeys\n",
    "def insert_parents_for_level(n, table_name):\n",
    "    query = f\"\"\"\n",
    "        INSERT INTO {table_name}\n",
    "        SELECT\n",
    "            SUBSTR(quadkey, 1, {n - 1}) AS parent_quadkey,\n",
    "            AVG(raster_1) AS raster_1,\n",
    "            AVG(raster_2) AS raster_2,\n",
    "            AVG(raster_3) AS raster_3,\n",
    "            AVG(raster_4) AS raster_4,\n",
    "            AVG(raster_5) AS raster_5,\n",
    "            AVG(raster_6) AS raster_6,\n",
    "            AVG(raster_7) AS raster_7,\n",
    "            AVG(raster_8) AS raster_8,\n",
    "            AVG(raster_9) AS raster_9,\n",
    "            AVG(raster_10) AS raster_10,\n",
    "            AVG(raster_11) AS raster_11,\n",
    "            AVG(raster_12) AS raster_12,\n",
    "            AVG(raster_13) AS raster_13,\n",
    "            AVG(raster_14) AS raster_14,\n",
    "            AVG(raster_15) AS raster_15,\n",
    "            AVG(raster_16) AS raster_16,\n",
    "            AVG(raster_17) AS raster_17,\n",
    "            AVG(raster_18) AS raster_18,\n",
    "            AVG(raster_19) AS raster_19,\n",
    "            AVG(raster_20) AS raster_20,\n",
    "            AVG(raster_21) AS raster_21,\n",
    "            AVG(raster_22) AS raster_22,\n",
    "            AVG(raster_23) AS raster_23,\n",
    "            AVG(raster_24) AS raster_24,\n",
    "            AVG(raster_25) AS raster_25,\n",
    "            AVG(raster_26) AS raster_26,\n",
    "            AVG(raster_27) AS raster_27,\n",
    "            AVG(raster_28) AS raster_28,\n",
    "            AVG(raster_29) AS raster_29,\n",
    "            AVG(raster_30) AS raster_30\n",
    "        FROM {table_name}\n",
    "        WHERE LENGTH(quadkey) = {n}\n",
    "        GROUP BY parent_quadkey\n",
    "        \"\"\"\n",
    "    con.execute(query)\n",
    "    con.commit()\n",
    "\n",
    "# Load all aggregation levels into database\n",
    "def load_all_aggregation_data_into_db(n):\n",
    "    for n in range(n, 0, -1):\n",
    "        print(f\"Processing aggregation for level {n}\")\n",
    "        insert_parents_for_level(n, \"data_slice_male_long_lat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset into DB for Zoom Level 13\n",
    "load_male_dataset_into_db()\n",
    "# load_all_aggregation_data_into_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load higher Quadkey levels into DB for level < 13\n",
    "load_all_aggregation_data_into_db(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
